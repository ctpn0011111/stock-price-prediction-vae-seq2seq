import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
import json
import os
from datetime import datetime
import time
import logging
import random


class CMCCrawler:
    def __init__(self):
        self.base_url = "https://www.cmc.com.vn/insight/tin-tuc/p"
        self.language_url = (
            "https://www.cmc.com.vn/language/vi"  # URL Ä‘á»ƒ chuyá»ƒn ngÃ´n ngá»¯
        )
        self.output_dir = "../../dataset/link/cmc_corporation"
        self.setup_logging()
        self.driver = None
        self.create_output_directory()
        self.max_retries = 3
        self.restart_interval = 20  # Restart driver every 20 pages
        self.language_switched = False  # Theo dÃµi viá»‡c chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯

    def setup_logging(self):
        """Thiáº¿t láº­p logging Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh crawl"""
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[logging.FileHandler("cmc_crawler.log"), logging.StreamHandler()],
        )
        self.logger = logging.getLogger(__name__)

    def setup_driver(self):
        """Thiáº¿t láº­p Selenium WebDriver vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u"""
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-plugins")
        chrome_options.add_argument(
            "--disable-images"
        )  # KhÃ´ng táº£i áº£nh Ä‘á»ƒ tiáº¿t kiá»‡m bÄƒng thÃ´ng
        chrome_options.add_argument("--memory-pressure-off")
        chrome_options.add_argument("--max_old_space_size=4096")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument(
            "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )

        # ThÃªm prefs Ä‘á»ƒ tá»‘i Æ°u hÃ³a
        prefs = {
            "profile.managed_default_content_settings.images": 2,  # Block images
            "profile.default_content_settings.popups": 0,
            "profile.managed_default_content_settings.media_stream": 2,
        }
        chrome_options.add_experimental_option("prefs", prefs)

        try:
            if self.driver:
                self.driver.quit()

            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.set_page_load_timeout(30)  # Timeout sau 30 giÃ¢y
            self.logger.info("WebDriver Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng")
            return True
        except Exception as e:
            self.logger.error(f"Lá»—i khá»Ÿi táº¡o WebDriver: {e}")
            return False

    def switch_to_vietnamese(self):
        """Chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ sang tiáº¿ng Viá»‡t báº±ng cÃ¡ch truy cáº­p trá»±c tiáº¿p URL"""
        try:
            self.logger.info("Äang chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ sang tiáº¿ng Viá»‡t...")

            # Truy cáº­p trá»±c tiáº¿p vÃ o URL chuyá»ƒn ngÃ´n ngá»¯
            if not self.safe_get_page(self.language_url):
                self.logger.error(
                    f"KhÃ´ng thá»ƒ truy cáº­p URL chuyá»ƒn ngÃ´n ngá»¯: {self.language_url}"
                )
                return False

            # Äá»£i má»™t chÃºt Ä‘á»ƒ trang xá»­ lÃ½ chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯
            time.sleep(3)

            # Kiá»ƒm tra xem cÃ³ Ä‘Æ°á»£c chuyá»ƒn hÆ°á»›ng vá» trang chá»§ khÃ´ng
            current_url = self.driver.current_url
            self.logger.info(f"URL hiá»‡n táº¡i sau khi chuyá»ƒn ngÃ´n ngá»¯: {current_url}")

            # ÄÃ¡nh dáº¥u Ä‘Ã£ chuyá»ƒn ngÃ´n ngá»¯ thÃ nh cÃ´ng
            self.language_switched = True
            self.logger.info("ÄÃ£ chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ sang tiáº¿ng Viá»‡t thÃ nh cÃ´ng!")

            return True

        except Exception as e:
            self.logger.error(f"Lá»—i khi chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯: {e}")
            # Váº«n Ä‘Ã¡nh dáº¥u Ä‘Ã£ thá»­ chuyá»ƒn Ä‘á»ƒ khÃ´ng thá»­ láº¡i
            self.language_switched = True
            return False

    def restart_driver(self):
        """Khá»Ÿi Ä‘á»™ng láº¡i WebDriver vÃ  chuyá»ƒn ngÃ´n ngá»¯ láº¡i"""
        self.logger.info("Äang khá»Ÿi Ä‘á»™ng láº¡i WebDriver...")
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass

        if self.setup_driver():
            # Chuyá»ƒn ngÃ´n ngá»¯ láº¡i sau khi restart driver
            self.language_switched = False
            return self.switch_to_vietnamese()
        return False

    def create_output_directory(self):
        """Táº¡o thÆ° má»¥c lÆ°u trá»¯ náº¿u chÆ°a tá»“n táº¡i"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            self.logger.info(f"ÄÃ£ táº¡o thÆ° má»¥c: {self.output_dir}")

    def safe_get_page(self, url, retries=0):
        """Truy cáº­p trang web má»™t cÃ¡ch an toÃ n vá»›i retry logic"""
        if retries >= self.max_retries:
            self.logger.error(
                f"ÄÃ£ thá»­ {self.max_retries} láº§n, khÃ´ng thá»ƒ truy cáº­p {url}"
            )
            return False

        try:
            if not self.driver:
                if not self.setup_driver():
                    return False

            self.driver.get(url)

            # Äá»£i trang load vá»›i timeout ngáº¯n hÆ¡n
            WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            return True

        except TimeoutException:
            self.logger.warning(
                f"Timeout khi táº£i trang {url}, thá»­ láº¡i... (láº§n {retries + 1})"
            )
            time.sleep(random.uniform(3, 7))  # Random delay
            return self.safe_get_page(url, retries + 1)

        except WebDriverException as e:
            self.logger.error(f"Lá»—i WebDriver: {e}")
            # Thá»­ khá»Ÿi Ä‘á»™ng láº¡i driver
            if "chrome not reachable" in str(e).lower() or "session" in str(e).lower():
                self.logger.info("Khá»Ÿi Ä‘á»™ng láº¡i WebDriver do lá»—i session...")
                if self.restart_driver():
                    return self.safe_get_page(url, retries + 1)
            return False

        except Exception as e:
            self.logger.error(f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")
            time.sleep(random.uniform(2, 5))
            return self.safe_get_page(url, retries + 1)

    def navigate_to_crawl_page_after_language_switch(self, url):
        """Äiá»u hÆ°á»›ng Ä‘áº¿n trang cáº§n crawl sau khi Ä‘á»•i ngÃ´n ngá»¯"""
        try:
            # Náº¿u chÆ°a chuyá»ƒn ngÃ´n ngá»¯, chuyá»ƒn trÆ°á»›c
            if not self.language_switched:
                if not self.switch_to_vietnamese():
                    self.logger.warning(
                        "KhÃ´ng thá»ƒ chuyá»ƒn ngÃ´n ngá»¯, tiáº¿p tá»¥c vá»›i ngÃ´n ngá»¯ hiá»‡n táº¡i"
                    )

            self.logger.info(f"Äang Ä‘iá»u hÆ°á»›ng Ä‘áº¿n trang crawl: {url}")

            # Sau khi chuyá»ƒn ngÃ´n ngá»¯, Ä‘iá»u hÆ°á»›ng Ä‘áº¿n trang cáº§n crawl
            if not self.safe_get_page(url):
                self.logger.error(f"KhÃ´ng thá»ƒ truy cáº­p trang crawl: {url}")
                return False

            self.logger.info("ÄÃ£ Ä‘iá»u hÆ°á»›ng Ä‘áº¿n trang crawl thÃ nh cÃ´ng!")
            return True

        except Exception as e:
            self.logger.error(f"Lá»—i khi Ä‘iá»u hÆ°á»›ng Ä‘áº¿n trang crawl: {e}")
            return False

    def check_page_exists(self, page_num):
        """Kiá»ƒm tra xem trang cÃ³ tá»“n táº¡i hay khÃ´ng"""
        url = f"{self.base_url}{page_num}"

        # Sá»­ dá»¥ng phÆ°Æ¡ng thá»©c má»›i Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng
        if not self.navigate_to_crawl_page_after_language_switch(url):
            return False

        try:
            # Kiá»ƒm tra xem cÃ³ pháº§n tá»­ figcaption vá»›i class cáº§n thiáº¿t khÃ´ng
            figcaptions = self.driver.find_elements(
                By.CSS_SELECTOR, "figcaption.content__cate__item__info"
            )

            if figcaptions:
                return True
            else:
                self.logger.warning(
                    f"Trang {page_num} khÃ´ng cÃ³ ná»™i dung hoáº·c Ä‘Ã£ háº¿t dá»¯ liá»‡u"
                )
                return False

        except Exception as e:
            self.logger.error(f"Lá»—i khi kiá»ƒm tra trang {page_num}: {e}")
            return False

    def extract_data_from_page(self, page_num):
        """TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« má»™t trang vá»›i error handling tá»‘t hÆ¡n"""
        url = f"{self.base_url}{page_num}"
        articles = []

        # Sá»­ dá»¥ng phÆ°Æ¡ng thá»©c má»›i Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng
        if not self.navigate_to_crawl_page_after_language_switch(url):
            return articles

        try:
            # Äá»£i elements load vá»›i timeout ngáº¯n hÆ¡n
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located(
                        (By.CSS_SELECTOR, "figcaption.content__cate__item__info")
                    )
                )
            except TimeoutException:
                self.logger.warning(f"KhÃ´ng tÃ¬m tháº¥y elements trÃªn trang {page_num}")
                return articles

            # Láº¥y HTML source vÃ  parse báº±ng BeautifulSoup
            soup = BeautifulSoup(self.driver.page_source, "html.parser")

            # TÃ¬m táº¥t cáº£ figcaption vá»›i class 'content__cate__item__info'
            figcaptions = soup.find_all(
                "figcaption", class_="content__cate__item__info"
            )

            for figcaption in figcaptions:
                try:
                    # TÃ¬m tháº» h3 vá»›i class 'content__cate__item__info__title'
                    h3_title = figcaption.find(
                        "h3", class_="content__cate__item__info__title"
                    )

                    if h3_title:
                        # TÃ¬m tháº» a trong h3
                        a_tag = h3_title.find("a")

                        if a_tag:
                            title = a_tag.get_text(strip=True)
                            href = a_tag.get("href", "")

                            # Xá»­ lÃ½ URL tÆ°Æ¡ng Ä‘á»‘i
                            if href.startswith("/"):
                                full_url = f"https://www.cmc.com.vn{href}"
                            else:
                                full_url = href

                            if title and full_url:  # Kiá»ƒm tra dá»¯ liá»‡u há»£p lá»‡
                                article = {"title": title, "url": full_url}
                                articles.append(article)

                except Exception as e:
                    self.logger.warning(
                        f"Lá»—i khi xá»­ lÃ½ má»™t bÃ i viáº¿t trÃªn trang {page_num}: {e}"
                    )
                    continue

            self.logger.info(
                f"ÄÃ£ trÃ­ch xuáº¥t {len(articles)} bÃ i viáº¿t tá»« trang {page_num}"
            )
            return articles

        except Exception as e:
            self.logger.error(f"Lá»—i khi trÃ­ch xuáº¥t dá»¯ liá»‡u tá»« trang {page_num}: {e}")
            return []

    def save_page_data(self, articles, page_num):
        """LÆ°u dá»¯ liá»‡u cá»§a má»™t trang vÃ o file JSON"""
        if not articles:
            return

        filename = f"cmc_page_{page_num}.json"
        filepath = os.path.join(self.output_dir, filename)

        # ThÃªm ID tá»± Ä‘á»™ng tÄƒng vÃ  ngÃ y crawl
        crawl_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        formatted_articles = []
        for idx, article in enumerate(articles, 1):
            formatted_article = {
                "id": f"page_{page_num}_{idx}",
                "title": article["title"],
                "url": article["url"],
                "crawl_date": crawl_date,
            }
            formatted_articles.append(formatted_article)

        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(formatted_articles, f, ensure_ascii=False, indent=2)

            self.logger.info(
                f"ÄÃ£ lÆ°u {len(formatted_articles)} bÃ i viáº¿t vÃ o {filepath}"
            )

        except Exception as e:
            self.logger.error(f"Lá»—i khi lÆ°u file {filepath}: {e}")

    def save_all_data(self, all_articles):
        """LÆ°u táº¥t cáº£ dá»¯ liá»‡u vÃ o má»™t file tá»•ng há»£p"""
        if not all_articles:
            return

        filename = "cmc_all_articles.json"
        filepath = os.path.join(self.output_dir, filename)

        # ThÃªm ID tá»± Ä‘á»™ng tÄƒng vÃ  ngÃ y crawl
        crawl_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        formatted_articles = []
        for idx, article in enumerate(all_articles, 1):
            formatted_article = {
                "id": idx,
                "title": article["title"],
                "url": article["url"],
                "crawl_date": crawl_date,
            }
            formatted_articles.append(formatted_article)

        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(formatted_articles, f, ensure_ascii=False, indent=2)

            self.logger.info(
                f"ÄÃ£ lÆ°u tá»•ng cá»™ng {len(formatted_articles)} bÃ i viáº¿t vÃ o {filepath}"
            )

        except Exception as e:
            self.logger.error(f"Lá»—i khi lÆ°u file tá»•ng há»£p {filepath}: {e}")

    def crawl_all_pages(self):
        """Crawl táº¥t cáº£ cÃ¡c trang tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i vá»›i improved error handling"""
        page_num = 1
        all_articles = []
        consecutive_failures = 0
        max_consecutive_failures = 5

        self.logger.info("Báº¯t Ä‘áº§u crawl dá»¯ liá»‡u tá»« CMC Corporation")

        # Khá»Ÿi táº¡o driver
        if not self.setup_driver():
            self.logger.error("KhÃ´ng thá»ƒ khá»Ÿi táº¡o WebDriver")
            return

        # Chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ sang tiáº¿ng Viá»‡t trÆ°á»›c khi báº¯t Ä‘áº§u crawl
        self.logger.info("Äang chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ sang tiáº¿ng Viá»‡t...")
        if not self.switch_to_vietnamese():
            self.logger.warning(
                "KhÃ´ng thá»ƒ chuyá»ƒn ngÃ´n ngá»¯, tiáº¿p tá»¥c vá»›i ngÃ´n ngá»¯ hiá»‡n táº¡i"
            )

        while True:
            self.logger.info(f"Äang crawl trang {page_num}...")

            # Khá»Ÿi Ä‘á»™ng láº¡i driver má»—i X trang Ä‘á»ƒ trÃ¡nh memory leak
            if page_num % self.restart_interval == 0:
                self.logger.info(
                    f"Khá»Ÿi Ä‘á»™ng láº¡i driver sau {self.restart_interval} trang..."
                )
                if not self.restart_driver():
                    self.logger.error("KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng láº¡i driver")
                    break

            # Kiá»ƒm tra xem trang cÃ³ tá»“n táº¡i khÃ´ng
            if not self.check_page_exists(page_num):
                consecutive_failures += 1
                if consecutive_failures >= max_consecutive_failures:
                    self.logger.info(
                        f"ÄÃ£ crawl xong. {consecutive_failures} trang liÃªn tiáº¿p khÃ´ng cÃ³ dá»¯ liá»‡u."
                    )
                    break
                else:
                    self.logger.warning(
                        f"Trang {page_num} khÃ´ng cÃ³ dá»¯ liá»‡u, thá»­ trang tiáº¿p theo..."
                    )
                    page_num += 1
                    continue

            # Reset counter khi tÃ¬m tháº¥y trang cÃ³ dá»¯ liá»‡u
            consecutive_failures = 0

            # TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« trang
            articles = self.extract_data_from_page(page_num)

            if articles:
                # LÆ°u dá»¯ liá»‡u trang hiá»‡n táº¡i
                self.save_page_data(articles, page_num)

                # ThÃªm vÃ o danh sÃ¡ch tá»•ng
                all_articles.extend(articles)

                self.logger.info(
                    f"ÄÃ£ hoÃ n thÃ nh trang {page_num} vá»›i {len(articles)} bÃ i viáº¿t"
                )
            else:
                self.logger.warning(f"Trang {page_num} khÃ´ng cÃ³ dá»¯ liá»‡u")

            # TÄƒng sá»‘ trang
            page_num += 1

            # Random delay Ä‘á»ƒ trÃ¡nh bá»‹ block
            time.sleep(random.uniform(2, 5))

        # LÆ°u file tá»•ng há»£p
        if all_articles:
            self.save_all_data(all_articles)
            self.logger.info(
                f"HoÃ n thÃ nh crawl! Tá»•ng cá»™ng {len(all_articles)} bÃ i viáº¿t tá»« {page_num-1} trang"
            )
        else:
            self.logger.warning("KhÃ´ng cÃ³ dá»¯ liá»‡u nÃ o Ä‘Æ°á»£c crawl")

    def crawl_pages_range(self, start_page, end_page):
        """Crawl cÃ¡c trang trong khoáº£ng tá»« start_page Ä‘áº¿n end_page"""
        all_articles = []

        # Kiá»ƒm tra input há»£p lá»‡
        if start_page < 1 or end_page < start_page:
            self.logger.error(
                "Sá»‘ trang khÃ´ng há»£p lá»‡. start_page pháº£i >= 1 vÃ  end_page >= start_page"
            )
            return

        self.logger.info(
            f"Báº¯t Ä‘áº§u crawl dá»¯ liá»‡u tá»« trang {start_page} Ä‘áº¿n trang {end_page}"
        )

        # Khá»Ÿi táº¡o driver
        if not self.setup_driver():
            self.logger.error("KhÃ´ng thá»ƒ khá»Ÿi táº¡o WebDriver")
            return

        # Chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ sang tiáº¿ng Viá»‡t trÆ°á»›c khi báº¯t Ä‘áº§u crawl
        self.logger.info("Äang chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ sang tiáº¿ng Viá»‡t...")
        if not self.switch_to_vietnamese():
            self.logger.warning(
                "KhÃ´ng thá»ƒ chuyá»ƒn ngÃ´n ngá»¯, tiáº¿p tá»¥c vá»›i ngÃ´n ngá»¯ hiá»‡n táº¡i"
            )

        for page_num in range(start_page, end_page + 1):
            self.logger.info(f"Äang crawl trang {page_num}...")

            # Khá»Ÿi Ä‘á»™ng láº¡i driver Ä‘á»‹nh ká»³
            if (
                page_num - start_page
            ) % self.restart_interval == 0 and page_num != start_page:
                self.logger.info(
                    f"Khá»Ÿi Ä‘á»™ng láº¡i driver sau {self.restart_interval} trang..."
                )
                if not self.restart_driver():
                    self.logger.error("KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng láº¡i driver")
                    break

            # Kiá»ƒm tra xem trang cÃ³ tá»“n táº¡i khÃ´ng
            if not self.check_page_exists(page_num):
                self.logger.warning(
                    f"Trang {page_num} khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng cÃ³ dá»¯ liá»‡u, bá» qua"
                )
                continue

            # TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« trang
            articles = self.extract_data_from_page(page_num)

            if articles:
                # LÆ°u dá»¯ liá»‡u trang hiá»‡n táº¡i
                self.save_page_data(articles, page_num)

                # ThÃªm vÃ o danh sÃ¡ch tá»•ng
                all_articles.extend(articles)

                self.logger.info(
                    f"ÄÃ£ hoÃ n thÃ nh trang {page_num} vá»›i {len(articles)} bÃ i viáº¿t"
                )
            else:
                self.logger.warning(f"Trang {page_num} khÃ´ng cÃ³ dá»¯ liá»‡u")

            # Random delay Ä‘á»ƒ trÃ¡nh bá»‹ block
            time.sleep(random.uniform(2, 5))

        # LÆ°u file tá»•ng há»£p
        if all_articles:
            self.save_all_data(all_articles)
            self.logger.info(
                f"HoÃ n thÃ nh crawl! Tá»•ng cá»™ng {len(all_articles)} bÃ i viáº¿t tá»« {end_page - start_page + 1} trang"
            )
        else:
            self.logger.warning("KhÃ´ng cÃ³ dá»¯ liá»‡u nÃ o Ä‘Æ°á»£c crawl")

    def close(self):
        """ÄÃ³ng WebDriver"""
        if self.driver:
            try:
                self.driver.quit()
                self.logger.info("ÄÃ£ Ä‘Ã³ng WebDriver")
            except:
                pass


def get_user_input():
    """Láº¥y input tá»« ngÆ°á»i dÃ¹ng Ä‘á»ƒ chá»n cháº¿ Ä‘á»™ crawl"""
    print("=== CMC Corporation Web Crawler ===")
    print("Chá»n cháº¿ Ä‘á»™ crawl:")
    print("1. Crawl táº¥t cáº£ trang (tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i)")
    print("2. Crawl theo khoáº£ng trang (chá»n trang báº¯t Ä‘áº§u vÃ  káº¿t thÃºc)")

    while True:
        try:
            choice = int(input("\nNháº­p lá»±a chá»n (1 hoáº·c 2): "))
            if choice in [1, 2]:
                return choice
            else:
                print("Vui lÃ²ng nháº­p 1 hoáº·c 2")
        except ValueError:
            print("Vui lÃ²ng nháº­p sá»‘ há»£p lá»‡")


def get_page_range():
    """Láº¥y khoáº£ng trang tá»« ngÆ°á»i dÃ¹ng"""
    while True:
        try:
            start_page = int(input("Nháº­p trang báº¯t Ä‘áº§u: "))
            if start_page < 1:
                print("Trang báº¯t Ä‘áº§u pháº£i >= 1")
                continue

            end_page = int(input("Nháº­p trang káº¿t thÃºc: "))
            if end_page < start_page:
                print("Trang káº¿t thÃºc pháº£i >= trang báº¯t Ä‘áº§u")
                continue

            return start_page, end_page
        except ValueError:
            print("Vui lÃ²ng nháº­p sá»‘ há»£p lá»‡")


def main():
    crawler = CMCCrawler()

    try:
        choice = get_user_input()

        if choice == 1:
            print("\nğŸš€ Báº¯t Ä‘áº§u crawl táº¥t cáº£ trang...")
            crawler.crawl_all_pages()
        else:
            start_page, end_page = get_page_range()
            print(f"\nğŸš€ Báº¯t Ä‘áº§u crawl tá»« trang {start_page} Ä‘áº¿n trang {end_page}...")
            crawler.crawl_pages_range(start_page, end_page)

    except KeyboardInterrupt:
        crawler.logger.info("Crawl bá»‹ dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng")
    except Exception as e:
        crawler.logger.error(f"Lá»—i khÃ´ng mong Ä‘á»£i: {e}")
    finally:
        crawler.close()


if __name__ == "__main__":
    main()
